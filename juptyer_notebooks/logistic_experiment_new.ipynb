{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <center> Particle Filter Experiment for the Logistic Growth Model ###"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T18:47:38.370990Z",
     "start_time": "2024-07-29T18:47:36.574575Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from jax.experimental.ode import odeint\n",
    "from scipy.stats import norm, poisson\n",
    "from scipy.integrate import solve_ivp\n",
    "\n",
    "import jax.numpy as jnp\n",
    "\n",
    "# save all the plots in a pdf\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "\n",
    "pp = PdfPages(\"logistic_dt_e10.pdf\")"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <center> Simulated Data"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "num_models = 3\n",
    "rng = np.random.default_rng(20)\n",
    "period = 365\n",
    "d = 365\n",
    "standard_deviation = 10\n",
    "\n",
    "\n",
    "# r(t) is the growth rate of the population at time t\n",
    "# max growth rate is 0.3 with time period of 365 days\n",
    "def r_t(t):\n",
    "    return 0.10 * jnp.sin(2 * jnp.pi * t / period)\n",
    "\n",
    "\n",
    "def growthEQ(y, t, pars):\n",
    "    r, k = pars\n",
    "    return r(t) * y * (1 - (y / k))\n",
    "\n",
    "\n",
    "# states is the initial population of the models\n",
    "states = np.ones(num_models)\n",
    "\n",
    "\n",
    "# k_vals is the carrying capacity of the population\n",
    "# k_vals = np.array([rng.integers(10,50) for _ in range(num_models)])\n",
    "k_vals = np.array([200, 25, 125])\n",
    "\n",
    "# data is the population of the models at each time step\n",
    "data = np.zeros((num_models, d))\n",
    "\n",
    "# first dimension is the parameters with the first row being the growth rate and the second row being the carrying capacity\n",
    "par = np.zeros((2, num_models, d))  # (num_parameters,num_models,len(time_series))\n",
    "\n",
    "data[:, 0] = jnp.ones((num_models,))\n",
    "\n",
    "data = odeint(\n",
    "    func=lambda y, t: growthEQ(y, t, (r_t, k_vals)),\n",
    "    y0=data[:, 0],\n",
    "    t=jnp.linspace(0, d, d),\n",
    ").T\n",
    "\n",
    "# extract daily data\n",
    "# add poisson noise to the data\n",
    "data = rng.poisson(data)\n",
    "\n",
    "# Create plot for data\n",
    "fig = plt.figure()\n",
    "plt.figure(figsize=(10, 6))\n",
    "for i in range(num_models):\n",
    "    plt.plot(np.arange(d), data[i, :], label=f\"Model {i+1} (k={k_vals[i]})\")\n",
    "\n",
    "\n",
    "plt.title(\"Simulated Population Growth with Poisson Noise\")\n",
    "plt.xlabel(\"Days\")\n",
    "plt.ylabel(\"Population\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "fig.savefig(pp, format=\"pdf\")\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.title(\"True $r_t$\")\n",
    "plt.xlabel(\"Days\")\n",
    "plt.grid(True)\n",
    "plt.plot([r_t(t) for t in range(d)])\n",
    "plt.show()\n",
    "fig.savefig(pp, format=\"pdf\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <center> Particle Filter"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Setup the particle distribution\n",
    "\n",
    "delta_t = 0.01\n",
    "num_particles = 10000\n",
    "# first dimension is the number of particles\n",
    "# second dimension is the number of species\n",
    "# third dimension is the state, r_t, and carrying capacity,\n",
    "# fourth dimension is the number of days\n",
    "log_particles = np.zeros((num_particles, num_models, 3, d))\n",
    "log_weights = np.zeros((num_particles, d))\n",
    "\n",
    "# initialize the particles\n",
    "log_particles[:, :, 0, 0] = rng.uniform(\n",
    "    0, 5, size=(num_particles, num_models)\n",
    ")  # initializer for the state\n",
    "log_particles[:, :, 1, 0] = rng.uniform(\n",
    "    -0.5, 0.5, size=(num_particles, 1)\n",
    ")  # initializer for r_t\n",
    "log_particles[:, :, 2, 0] = rng.integers(\n",
    "    10, 500, size=(num_particles, num_models)\n",
    ")  # initializer for carrying capacity k\n",
    "\n",
    "\n",
    "def growthEQ(y, t, par):\n",
    "    return par[:, :, 0] * y * (1 - (y / par[:, :, 1]))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def jacobian(δ: np.ndarray):\n",
    "    \"\"\"\n",
    "    The jacobian logarithm, used in log likelihood normalization and\n",
    "    resampling processes.\n",
    "\n",
    "    Args:\n",
    "        δ: An array of values to sum\n",
    "\n",
    "    Returns:\n",
    "        The vector of partial sums of δ.\n",
    "    \"\"\"\n",
    "    n = len(δ)\n",
    "    Δ = np.zeros(n)\n",
    "    Δ[0] = δ[0]\n",
    "    for i in range(1, n):\n",
    "        Δ[i] = max(δ[i], Δ[i - 1]) + np.log(1 + np.exp(-1 * np.abs(δ[i] - Δ[i - 1])))\n",
    "    return Δ\n",
    "\n",
    "\n",
    "def log_norm(log_weights):\n",
    "    \"\"\"\n",
    "    Normalizes the probability space using the jacobian logarithm as\n",
    "    defined in jacobian().\n",
    "    \"\"\"\n",
    "    normalized = jacobian(log_weights)[-1]\n",
    "    log_weights -= normalized\n",
    "    return log_weights"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Running the particle filter\n",
    "# OU process parameters, hyperparameters\n",
    "OU_Params = {\"theta\": 0.05, \"mean\": 0.0, \"diffusion\": 0.05}\n",
    "\n",
    "# h is the hyperparameter for the static paramter estimation\n",
    "h = 0.1\n",
    "a = np.sqrt(1 - h**2)\n",
    "\n",
    "for time_index in range(d):  # Loop over the number of days in the data\n",
    "\n",
    "    print(f\"Iteration: {time_index} \\r\")\n",
    "\n",
    "    ###Forecast\n",
    "    if time_index > 0:\n",
    "\n",
    "        # initialize with previous values\n",
    "        log_particles[:, :, 0:2, time_index] = log_particles[:, :, 0:2, time_index - 1]\n",
    "\n",
    "        for _ in range(int(1 / delta_t)):\n",
    "\n",
    "            # Forward Euler integration\n",
    "            log_particles[:, :, 0, time_index] = log_particles[\n",
    "                :, :, 0, time_index\n",
    "            ] + delta_t * growthEQ(\n",
    "                log_particles[:, :, 0, time_index],\n",
    "                time_index,\n",
    "                log_particles[:, :, 1:, time_index - 1],\n",
    "            )\n",
    "\n",
    "            # Need the weiner process fixed for rng\n",
    "            dW = rng.normal(0, scale=np.sqrt(delta_t), size=(num_particles))\n",
    "\n",
    "            log_particles[:, :, 1, time_index] = (\n",
    "                log_particles[:, 0, 1, time_index]\n",
    "                + OU_Params[\"theta\"]\n",
    "                * (OU_Params[\"mean\"] - log_particles[:, 0, 1, time_index])\n",
    "                * delta_t\n",
    "                + OU_Params[\"diffusion\"] * dW\n",
    "            ).reshape((num_particles, 1))\n",
    "\n",
    "        \"\"\"Log domain static parameter computation\"\"\"\n",
    "        num_statics = log_particles[:, :, 2, time_index - 1].shape[1]\n",
    "\n",
    "        deltas = np.zeros((num_particles, num_statics))\n",
    "\n",
    "        \"\"\"Now compute the deltas, we must log each parameter \"\"\"\n",
    "        for i in range(num_statics):\n",
    "            sub_theta = np.log(log_particles[:, i, 2, time_index - 1])\n",
    "            \"\"\"sub_theta shape is (particle_count,1)\"\"\"\n",
    "\n",
    "            for j in range(num_particles):\n",
    "                log_theta = sub_theta[j]\n",
    "                log_log = np.log(np.abs(log_theta))\n",
    "                \"\"\"Absolute value here accounts for taking log of a negative number, \n",
    "                log_theta is surely negative. We take the complex part outside the computation. \"\"\"\n",
    "\n",
    "                \"\"\"Make sure to add the weights to the deltas. Must be the log weights for this to work properly. \"\"\"\n",
    "                deltas[j, i] = log_weights[j, time_index - 1] + log_log\n",
    "\n",
    "        ξ = []\n",
    "        for i in range(num_statics):\n",
    "            \"\"\"Compute ξ elementwise and multiply by -1 to account for the sign change.\"\"\"\n",
    "            ξ.append(np.exp(jacobian(deltas[:, i])))\n",
    "\n",
    "        \"\"\"Need to pull the last element, remember jacob returns the array of partial sums. \"\"\"\n",
    "        ξ = np.array(ξ)[:, -1]\n",
    "\n",
    "        psis = np.array(np.log(log_particles[:, :, 2, time_index - 1]) - ξ)\n",
    "\n",
    "        matrix_set = []\n",
    "        for i in range(num_particles):\n",
    "            matrix_set.append(np.outer(psis[i, :], psis[i, :]))\n",
    "        matrix_set = np.array(matrix_set)\n",
    "\n",
    "        Σ = np.zeros((num_statics, num_statics))\n",
    "\n",
    "        C = 100\n",
    "\n",
    "        for i in range(num_statics):\n",
    "            for j in range(num_statics):\n",
    "                if i != j:\n",
    "\n",
    "                    deltas_Y = (\n",
    "                        np.log(\n",
    "                            matrix_set[:, i, j] + C * np.ones_like(matrix_set[:, i, j])\n",
    "                        )\n",
    "                        + log_weights[:, time_index - 1]\n",
    "                    )\n",
    "\n",
    "                    deltas_Z = log_weights[:, time_index - 1] + np.log(\n",
    "                        C * np.ones_like(log_weights[:, time_index - 1])\n",
    "                    )\n",
    "\n",
    "                    Z = np.exp(jacobian(deltas_Z)[-1])\n",
    "\n",
    "                    Σ[i, j] = np.exp(jacobian(deltas_Y)[-1]) - Z\n",
    "\n",
    "                else:\n",
    "                    \"\"\"On the diagonal the elements are guaranteed to be positive, so there isn't a\"\"\"\n",
    "\n",
    "                    deltas = (\n",
    "                        np.log(matrix_set[:, i, j]) + log_weights[:, time_index - 1]\n",
    "                    )\n",
    "                    Σ[i, j] = np.exp(jacobian(deltas)[-1])\n",
    "\n",
    "        \"\"\"Static parameter perturbation\"\"\"\n",
    "        for p in range(num_particles):\n",
    "\n",
    "            standard_variates = rng.standard_normal((num_models,)).reshape(\n",
    "                -1, num_models\n",
    "            )\n",
    "\n",
    "            (u, s, v) = np.linalg.svd((h**2) * Σ)\n",
    "\n",
    "            log_samples = np.dot(standard_variates, np.sqrt(s)[:, None] * v)\n",
    "            log_samples += (\n",
    "                a * np.log(log_particles[p, :, 2, time_index - 1]) + (1 - a) * ξ\n",
    "            )\n",
    "            log_particles[p, :, 2, time_index] = np.exp(log_samples)\n",
    "\n",
    "    \"\"\"Resampling\"\"\"\n",
    "    for model in range(num_models):\n",
    "        log_weights[:, time_index] += norm.logpdf(\n",
    "            data[model, time_index],\n",
    "            log_particles[:, model, 0, time_index],\n",
    "            scale=standard_deviation,\n",
    "        )\n",
    "\n",
    "    # Normalize the weights\n",
    "    log_weights[:, time_index] = log_norm(log_weights[:, time_index])\n",
    "\n",
    "    # setup the resampling indices\n",
    "    resampling_indices_log = np.zeros(num_particles, dtype=int)\n",
    "    cdf_log = jacobian(log_weights[:, time_index])\n",
    "\n",
    "    u = rng.uniform(0, 1 / num_particles)\n",
    "\n",
    "    \"\"\"Log resample\"\"\"\n",
    "    i = 0\n",
    "    for j in range(num_particles):\n",
    "        r_log = np.log(u + (1 / num_particles) * j)\n",
    "        while r_log > cdf_log[i]:\n",
    "            i += 1\n",
    "        resampling_indices_log[j] = i\n",
    "\n",
    "    \"\"\"Reindexing the array\"\"\"\n",
    "    log_particles_copy = log_particles[:, :, :, time_index].copy()\n",
    "    log_particles[:, :, :, time_index] = log_particles_copy[\n",
    "        resampling_indices_log, :, :\n",
    "    ]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "print(log_weights[:, time_index])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "for model in range(num_models):\n",
    "    fig = plt.figure()\n",
    "    # plot the true data in scatter plot with a smaller size\n",
    "    plt.scatter(np.arange(d), data[model, :], s=4)\n",
    "    # plot the mean, and make the line thinner\n",
    "    plt.plot(np.average(lin_particles[:, model, 0, :], weights=lin_weights, axis=0))\n",
    "    # plot the uncertainty\n",
    "    plt.fill_between(\n",
    "        np.arange(d),\n",
    "        np.percentile(lin_particles[:, model, 0, :], 5, axis=0),\n",
    "        np.percentile(lin_particles[:, model, 0, :], 95, axis=0),\n",
    "        alpha=0.5,\n",
    "    )\n",
    "    # add a title\n",
    "    plt.title(f\"Species {model} \" + \"with 90% CI Lin Domain\")\n",
    "    # add a legend to the top right\n",
    "    plt.legend([\"True Data\", \"PF Mean\", \"Uncertainty\"], loc=\"upper right\")\n",
    "    plt.show()\n",
    "    fig.savefig(pp, format=\"pdf\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "for model in range(num_models):\n",
    "    fig = plt.figure()\n",
    "    # plot the true data in scatter plot with a smaller size\n",
    "    plt.scatter(np.arange(d), data[model, :], s=4)\n",
    "    # plot the mean, and make the line thinner\n",
    "    plt.plot(np.average(log_particles[:, model, 0, :], weights=log_weights, axis=0))\n",
    "    # plot the uncertainty\n",
    "    plt.fill_between(\n",
    "        np.arange(d),\n",
    "        np.percentile(log_particles[:, model, 0, :], 5, axis=0),\n",
    "        np.percentile(log_particles[:, model, 0, :], 95, axis=0),\n",
    "        alpha=0.5,\n",
    "    )\n",
    "    # add a title\n",
    "    plt.title(f\"Species {model} \" + \"with 90% CI Log Domain\")\n",
    "    # add a legend to the top right\n",
    "    plt.legend([\"True Data\", \"PF Mean\", \"Uncertainty\"], loc=\"upper right\")\n",
    "    plt.show()\n",
    "    fig.savefig(pp, format=\"pdf\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "fig = plt.figure()\n",
    "plt.plot([r_t(t) for t in range(d)])\n",
    "plt.plot(np.average(log_particles[:, model, 1, :], weights=log_weights, axis=0))\n",
    "# plot the uncertainty\n",
    "plt.fill_between(\n",
    "    np.arange(d),\n",
    "    np.percentile(log_particles[:, 0, 1, :], 5, axis=0),\n",
    "    np.percentile(log_particles[:, 0, 1, :], 95, axis=0),\n",
    "    alpha=0.5,\n",
    ")\n",
    "# add a title\n",
    "plt.title(\n",
    "    f\"r(t) with 90% CI Log Domain.  Num particles: {num_particles}, STD: {standard_deviation}, OU Params: {OU_Params}\"\n",
    ")\n",
    "# add a legend to the top right\n",
    "plt.legend([\"True Data\", \"PF Mean\", \"Uncertainty\"], loc=\"upper right\")\n",
    "plt.show()\n",
    "fig.savefig(pp, format=\"pdf\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "fig = plt.figure()\n",
    "plt.plot([r_t(t) for t in range(d)])\n",
    "plt.plot(np.average(lin_particles[:, 0, 1, :], weights=lin_weights, axis=0))\n",
    "# plot the uncertainty\n",
    "plt.fill_between(\n",
    "    np.arange(d),\n",
    "    np.percentile(lin_particles[:, 0, 1, :], 5, axis=0),\n",
    "    np.percentile(lin_particles[:, 0, 1, :], 95, axis=0),\n",
    "    alpha=0.5,\n",
    ")\n",
    "# add a title\n",
    "plt.title(\n",
    "    f\"r(t) with 90% CI Log Domain.  Num particles: {num_particles}, STD: {standard_deviation}, OU Params: {OU_Params}\"\n",
    ")\n",
    "# add a legend to the top right\n",
    "plt.legend([\"True Data\", \"PF Mean\", \"Uncertainty\"], loc=\"upper right\")\n",
    "plt.show()\n",
    "fig.savefig(pp, format=\"pdf\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "for model in range(num_models):\n",
    "    fig = plt.figure()\n",
    "    plt.hlines(k_vals[model], xmin=0, xmax=d)\n",
    "    plt.plot(\n",
    "        np.average(lin_particles[:, model, 2, :], weights=lin_weights, axis=0),\n",
    "        color=\"orange\",\n",
    "    )\n",
    "    # plot the uncertainty\n",
    "    plt.fill_between(\n",
    "        np.arange(d),\n",
    "        np.percentile(lin_particles[:, model, 2, :], 5, axis=0),\n",
    "        np.percentile(lin_particles[:, model, 2, :], 95, axis=0),\n",
    "        alpha=0.5,\n",
    "    )\n",
    "    # add a title\n",
    "    plt.title(\"Carrying Capacity of species\" + str(model) + \" with 90% CI Lin Domain\")\n",
    "    # add a legend to the top right\n",
    "    plt.legend([\"True Data\", \"PF Mean\", \"Uncertainty\"], loc=\"upper right\")\n",
    "    plt.show()\n",
    "    fig.savefig(pp, format=\"pdf\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "for model in range(num_models):\n",
    "    fig = plt.figure()\n",
    "    plt.hlines(k_vals[model], xmin=0, xmax=d)\n",
    "    plt.plot(\n",
    "        np.average(log_particles[:, model, 2, :], weights=log_weights, axis=0),\n",
    "        color=\"orange\",\n",
    "    )\n",
    "    # plot the uncertainty\n",
    "    plt.fill_between(\n",
    "        np.arange(d),\n",
    "        np.percentile(log_particles[:, model, 2, :], 5, axis=0),\n",
    "        np.percentile(log_particles[:, model, 2, :], 95, axis=0),\n",
    "        alpha=0.5,\n",
    "    )\n",
    "    # add a title\n",
    "    plt.title(\"Carrying Capacity of species\" + str(model) + \" with 90% CI Log Domain\")\n",
    "    # add a legend to the top right\n",
    "    plt.legend([\"True Data\", \"PF Mean\", \"Uncertainty\"], loc=\"upper right\")\n",
    "    plt.show()\n",
    "    fig.savefig(pp, format=\"pdf\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "###Root Mean Square Error\n",
    "colors = [\"b\", \"g\", \"r\", \"c\", \"m\", \"y\", \"k\", \"w\", \"b\", \"g\"]\n",
    "\n",
    "# compute rsme for each location across time t\n",
    "rmse_lin = np.zeros((d, num_models))\n",
    "rmse_log = np.zeros((d, num_models))\n",
    "\n",
    "for loc in range(num_models):\n",
    "    rmse_log[:, loc] = np.sqrt(\n",
    "        (\n",
    "            np.average(log_particles[:, loc, 0, :], weights=np.exp(log_weights), axis=0)\n",
    "            - data[loc, :]\n",
    "        )\n",
    "        ** 2\n",
    "    )\n",
    "    rmse_lin[:, loc] = np.sqrt(\n",
    "        (\n",
    "            np.average(lin_particles[:, loc, 0, :], weights=lin_weights, axis=0)\n",
    "            - data[loc, :]\n",
    "        )\n",
    "        ** 2\n",
    "    )\n",
    "    # print(f\"Location {loc} Time {t} RMSE log: {rmse_log} RMSE lin: {rmse_lin}\")\n",
    "\n",
    "# plot the rmse across time for each location in one figure\n",
    "for loc in range(num_models):\n",
    "    plt.title(f\"RMSE for State {loc}\")\n",
    "    plt.plot(rmse_log[:, loc], \"--\", label=\"log\", color=colors[loc])\n",
    "    plt.plot(rmse_lin[:, loc], label=\"lin\", color=colors[loc])\n",
    "    plt.legend()\n",
    "    print(np.sum(rmse_log[:, loc] - rmse_lin[:, loc]))\n",
    "    plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "###Root Mean Square Error\n",
    "colors = [\"b\", \"g\", \"r\", \"c\", \"m\", \"y\", \"k\", \"w\", \"b\", \"g\"]\n",
    "\n",
    "# compute rsme for each location across time t\n",
    "rmse_lin = np.zeros((d, num_models))\n",
    "rmse_log = np.zeros((d, num_models))\n",
    "\n",
    "real = [r_t(t) for t in range(d)]\n",
    "\n",
    "for loc in range(num_models):\n",
    "    rmse_log[:, loc] = np.sqrt(\n",
    "        (\n",
    "            np.average(log_particles[:, loc, 1, :], weights=np.exp(log_weights), axis=0)\n",
    "            - real\n",
    "        )\n",
    "        ** 2\n",
    "    )\n",
    "    rmse_lin[:, loc] = np.sqrt(\n",
    "        (np.average(lin_particles[:, loc, 1, :], weights=lin_weights, axis=0) - real)\n",
    "        ** 2\n",
    "    )\n",
    "    # print(f\"Location {loc} Time {t} RMSE log: {rmse_log} RMSE lin: {rmse_lin}\")\n",
    "\n",
    "# plot the rmse across time for each location in one figure\n",
    "for loc in range(num_models):\n",
    "    plt.title(f\"RMSE for r_t {loc}\")\n",
    "    plt.plot(rmse_log[:, loc], \"--\", label=\"log\", color=colors[loc])\n",
    "    plt.plot(rmse_lin[:, loc], label=\"lin\", color=colors[loc])\n",
    "    plt.legend()\n",
    "    print(np.sum(rmse_log[:, loc] - rmse_lin[:, loc]))\n",
    "    plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "###Root Mean Square Error\n",
    "colors = [\"b\", \"g\", \"r\", \"c\", \"m\", \"y\", \"k\", \"w\", \"b\", \"g\"]\n",
    "\n",
    "# compute rsme for each location across time t\n",
    "rmse_lin = np.zeros((d, num_models))\n",
    "rmse_log = np.zeros((d, num_models))\n",
    "\n",
    "for loc in range(num_models):\n",
    "    rmse_log[:, loc] = np.sqrt(\n",
    "        (\n",
    "            np.average(log_particles[:, loc, 2, :], weights=np.exp(log_weights), axis=0)\n",
    "            - k_vals[loc]\n",
    "        )\n",
    "        ** 2\n",
    "    )\n",
    "    rmse_lin[:, loc] = np.sqrt(\n",
    "        (\n",
    "            np.average(lin_particles[:, loc, 2, :], weights=lin_weights, axis=0)\n",
    "            - k_vals[loc]\n",
    "        )\n",
    "        ** 2\n",
    "    )\n",
    "    # print(f\"Location {loc} Time {t} RMSE log: {rmse_log} RMSE lin: {rmse_lin}\")\n",
    "\n",
    "# plot the rmse across time for each location in one figure\n",
    "for loc in range(num_models):\n",
    "    plt.title(f\"RMSE for k {loc}\")\n",
    "    plt.plot(rmse_log[:, loc], \"--\", label=\"log\", color=colors[loc])\n",
    "    plt.plot(rmse_lin[:, loc], label=\"lin\", color=colors[loc])\n",
    "    plt.legend()\n",
    "    print(np.sum(rmse_log[:, loc] - rmse_lin[:, loc]))\n",
    "    plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "pp.close()"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
